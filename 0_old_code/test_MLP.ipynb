{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from opart_functions import SquaredHingeLoss\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from opart_functions import get_acc_rate, get_err_df, gen_data_dict, tune_lldas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "features_fold1_path = 'training_data/genome/seq_features.csv'\n",
    "features_fold2_path = 'training_data/genome/seq_features.csv'  \n",
    "target_fold1_path = 'training_data/genome/target_fold1.csv'\n",
    "target_fold2_path = 'training_data/genome/target_fold2.csv'\n",
    "\n",
    "# sequences and labels\n",
    "seqs_path   = 'raw_data/genome/signals.csv'\n",
    "labels_path = 'raw_data/genome/labels.csv'\n",
    "\n",
    "# err for each log_lambda\n",
    "err_fold1_path = 'training_data/genome/errors_fold1.csv'\n",
    "err_fold2_path = 'training_data/genome/errors_fold2.csv'\n",
    "\n",
    "# writing accuracy rate path\n",
    "acc_rate_path = 'acc_rate/genome.csv'\n",
    "\n",
    "# path to write df to csv\n",
    "output_df_path = 'record_dataframe/genome/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sequence and label dictionary\n",
    "seqs_dict   = gen_data_dict(seqs_path)\n",
    "labels_dict = gen_data_dict(labels_path)\n",
    "\n",
    "# getting dataframe of error count for each log_lambda\n",
    "err_fold1_df = pd.read_csv(err_fold1_path)\n",
    "err_fold2_df = pd.read_csv(err_fold2_path)\n",
    "\n",
    "# features_df\n",
    "features_df_fold1 = pd.read_csv(features_fold1_path)\n",
    "features_df_fold2 = pd.read_csv(features_fold2_path)\n",
    "\n",
    "# targets_df\n",
    "target_df_fold1 = pd.read_csv(target_fold1_path)\n",
    "target_df_fold2 = pd.read_csv(target_fold2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_low_1  = torch.Tensor(target_df_fold1.iloc[:, 1:2].to_numpy())\n",
    "targets_high_1 = torch.Tensor(target_df_fold1.iloc[:, 2:3].to_numpy())\n",
    "targets_low_2  = torch.Tensor(target_df_fold2.iloc[:, 1:2].to_numpy())\n",
    "targets_high_2 = torch.Tensor(target_df_fold2.iloc[:, 2:3].to_numpy())\n",
    "\n",
    "target_fold1 = torch.cat((targets_low_1, targets_high_1), dim=1)\n",
    "target_fold2 = torch.cat((targets_low_2, targets_high_2), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    torch.manual_seed(123)\n",
    "    def __init__(self, input_size, hidden_layers, hidden_size):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.input_size    = input_size\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_size   = hidden_size\n",
    "\n",
    "        if(self.hidden_layers == 0):\n",
    "            self.linear_model = nn.Linear(input_size, 1)                                                        # Define linear model\n",
    "        else:\n",
    "            self.input_layer = nn.Linear(input_size, hidden_size)                                               # Define input layer\n",
    "            self.hidden = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for _ in range(hidden_layers-1)])  # Define hidden layers\n",
    "            self.output_layer = nn.Linear(hidden_size, 1)                                                       # Define output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if(self.hidden_layers == 0):\n",
    "            return self.linear_model(x)\n",
    "        else:\n",
    "            x = torch.relu(self.input_layer(x))\n",
    "            for layer in self.hidden:\n",
    "                x = torch.relu(layer(x))\n",
    "            x = self.output_layer(x)\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def investigate_model(input_size, hidden_layers, hidden_size, batch_size, feature, targets, test_fold, seqs_dict, labels_dict, err_df, n_ites=1):\n",
    "    torch.manual_seed(123)\n",
    "    # prepare training dataset\n",
    "    dataset    = TensorDataset(feature, targets)\n",
    "    dataloader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "\n",
    "    # Instantiate model, loss function and opimizer\n",
    "    model = MLPModel(input_size, hidden_layers, hidden_size)\n",
    "    criterion = SquaredHingeLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    # Training loop\n",
    "    rates = []\n",
    "    for i in range(n_ites + 1):\n",
    "        total_loss = 0\n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            lldas = model(feature).numpy().reshape(-1)\n",
    "        lldas = tune_lldas(lldas)\n",
    "        \n",
    "        if(i%1 == 0):\n",
    "            df = get_err_df(lldas, test_fold, seqs_dict, labels_dict, err_df)\n",
    "            rate = get_acc_rate(df)\n",
    "            rates.append(rate)\n",
    "            print(i, total_loss/len(dataloader), rate)\n",
    "    \n",
    "    return rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature\n",
    "chosen_feature = ['std_deviation', 'length', 'sum_diff', 'range_value', 'abs_skewness']\n",
    "X = features_df_fold1.iloc[:, 1:][chosen_feature].to_numpy()\n",
    "X0 = X[:, 0]\n",
    "X0 = np.log(X0).reshape(-1, 1)\n",
    "X1 = X[:, 1]\n",
    "X1 = np.log(np.log(X1)).reshape(-1, 1)\n",
    "X2 = X[:, 2]\n",
    "X2 = np.log(np.log(X2)).reshape(-1, 1)\n",
    "X3 = X[:, 3]\n",
    "X3 = np.log(X3).reshape(-1, 1)\n",
    "X4 = X[:, 4]\n",
    "X4 = np.log(X4).reshape(-1, 1)\n",
    "\n",
    "X = np.concatenate([X0, X1, X2, X3, X4], axis=1)\n",
    "mean = np.mean(X, axis=0)\n",
    "std_dev = np.std(X, axis=0)\n",
    "X = (X-mean)/std_dev\n",
    "X = torch.Tensor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fold1, test_fold2\n",
    "rates_fold2 = investigate_model(X.shape[1], 0, 0, 1, X, target_fold1, 2, seqs_dict, labels_dict, err_fold2_df, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fold2, test_fold1\n",
    "rates_fold1 = investigate_model(X.shape[1], 0, 0, 1, X, target_fold2, 1, seqs_dict, labels_dict, err_fold1_df, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fold1, test_fold1, batch 1\n",
    "rates_fold1_train = investigate_model(X.shape[1], 0, 0, 1, X, target_fold1, 1, seqs_dict, labels_dict, err_fold1_df, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fold1, test_fold1, batch 2\n",
    "rates_fold1_train = investigate_model(X.shape[1], 0, 0, 2, X, target_fold1, 1, seqs_dict, labels_dict, err_fold1_df, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fold1, test_fold1, batch 3\n",
    "rates_fold1_train = investigate_model(X.shape[1], 0, 0, 2, X, target_fold1, 1, seqs_dict, labels_dict, err_fold1_df, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fold1, test_fold1, batch 4\n",
    "rates_fold1_train = investigate_model(X.shape[1], 0, 0, 4, X, target_fold1, 1, seqs_dict, labels_dict, err_fold1_df, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fold1, test_fold1, batch 8\n",
    "rates_fold1_train = investigate_model(X.shape[1], 0, 0, 8, X, target_fold1, 1, seqs_dict, labels_dict, err_fold1_df, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fold2, test_fold2 batch 1\n",
    "rates_fold2_train = investigate_model(X.shape[1], 0, 0, 1, X, target_fold2, 2, seqs_dict, labels_dict, err_fold2_df, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fold2, test_fold2 batch 2\n",
    "rates_fold2_train = investigate_model(X.shape[1], 0, 0, 2, X, target_fold2, 2, seqs_dict, labels_dict, err_fold2_df, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fold2, test_fold2 batch 4\n",
    "rates_fold2_train = investigate_model(X.shape[1], 0, 0, 4, X, target_fold2, 2, seqs_dict, labels_dict, err_fold2_df, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fold2, test_fold2 batch 16\n",
    "rates_fold2_train = investigate_model(X.shape[1], 0, 0, 16, X, target_fold2, 2, seqs_dict, labels_dict, err_fold2_df, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
